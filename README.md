## Data set [Got it from here](https://www.kaggle.com/datasets/purusinghvi/email-spam-classification-dataset) 

The objective of this repo is not to get state-of-the-art results. It is mainly focused on improving training accuracy and understanding how.

This project was implemented parallelly through my learning process. to get a deeper understanding of how actually the field of NLP became accurate and outperformed the human brain.

Looking at the evaluation of NLP. I just want to have a deeper understanding of every architecture. starting from RNNs to BERT.


The project is all about implementing all the NLP techniques.
> 1. Bag of words
> 2. Term frequency and Inverse document frequency
> 3. word to vec
> 4. Bi-directional LSTM
> 5. BERT

I mainly focused on how actually these techniques work and their internal mechanisms
